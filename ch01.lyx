#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass scrbook
\use_default_options true
\master note.lyx
\begin_modules
enumitem
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
filename "macros.lyx"

\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Standard
Different kinds of tasks of machine learning:
\end_layout

\begin_layout Itemize
supervised learning: known input and target vectors
\end_layout

\begin_layout Itemize
classification: output is one of a finite number of discrete categories
\end_layout

\begin_deeper
\begin_layout Itemize
regression: output is one or more continuous variables
\end_layout

\end_deeper
\begin_layout Itemize
unsupervised learning: no corresponding target values
\end_layout

\begin_deeper
\begin_layout Itemize
clustering: discover groups of similar examples within the data
\end_layout

\begin_layout Itemize
density estimation: determine the distribution of data within the input
 space
\end_layout

\begin_layout Itemize
dimension reduction
\end_layout

\end_deeper
\begin_layout Itemize
reinforcement learning: finding suitable actions to take in a given situation
 in order to maximize a reward
\end_layout

\begin_layout Section
Example: Polynomial Curve Fitting
\end_layout

\begin_layout Standard
In regression problems, we can use a polynomial function
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y(x,{\bf w})=w_{0}+w_{1}+w_{2}x^{2}+\ldots+w_{M}x^{M}=\sum_{j=0}^{M}w_{j}x^{j}\label{eq:y(x,w)}
\end{equation}

\end_inset

 to fit the underlying function.
\end_layout

\begin_layout Standard
We need to minimize the 
\emph on
error function
\emph default
 
\begin_inset Formula 
\begin{equation}
E({\bf w})=\frac{1}{2}\sum_{n=1}^{N}\{y(x_{n},{\bf w})-t_{n}\}^{2}\label{eq:E(w)}
\end{equation}

\end_inset

in which unique solution 
\begin_inset Formula ${\bf w^{*}}$
\end_inset

 can be found in closed form.
\end_layout

\begin_layout Standard
The root-mean-square (RMS) error is defined by 
\begin_inset Formula 
\[
E_{{\rm RMS}}=\sqrt{2E({\bf w^{*})/N}}
\]

\end_inset


\end_layout

\begin_layout Standard
When 
\begin_inset Formula $M$
\end_inset

 is large, 
\emph on
over-fitting
\emph default
 occurs, i.e.
 
\begin_inset Formula $E_{RMS}$
\end_inset

 against test data becomes large.
 One technique to control over-fitting is 
\emph on
regularization
\emph default
, by adding a penalty term to the error function 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:E(w)"

\end_inset

 in order to discourage the coefficients from reaching large values:
\begin_inset Formula 
\begin{equation}
\widetilde{E}({\bf w})=\frac{1}{2}\sum_{n=1}^{N}\{y(x_{n},{\bf w})-t_{n}\}^{2}+\frac{\lambda}{2}\left\Vert {\bf w}\right\Vert ^{2}\label{eq:regularized E(w)}
\end{equation}

\end_inset


\end_layout

\begin_layout Section
Probability Theory
\end_layout

\begin_layout Standard
Equations for probability:
\end_layout

\begin_layout Itemize
Sum rule 
\begin_inset Formula 
\[
p(X)=\sum_{Y}p(X,Y)
\]

\end_inset


\end_layout

\begin_layout Itemize
Product rule 
\begin_inset Formula 
\[
p(X,Y)=p(Y|X)p(X)
\]

\end_inset


\end_layout

\begin_layout Itemize
Bayes' theorem 
\begin_inset Formula 
\begin{equation}
p(Y|X)=\frac{p(X|Y)p(Y)}{p(X)}\label{eq:bayes}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The denominator in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:bayes"

\end_inset

 can be expressed in terms of the quantities appearing in the numerator
\begin_inset Formula 
\[
p(X)=\sum_{Y}p(X|Y)p(Y)
\]

\end_inset


\end_layout

\begin_layout Standard
We can view the denominator in Bayes' theorem as being the normalization
 constant required to ensure that the sum of the conditional probability
 on the left-hand side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:bayes"

\end_inset

 over all values of 
\begin_inset Formula $Y$
\end_inset

 equals 
\begin_inset Formula $1$
\end_inset

.
\end_layout

\begin_layout Standard
Before any observation, we have a probability of a certain event 
\begin_inset Formula $Y$
\end_inset

, this is called 
\emph on
prior probability
\emph default
 
\begin_inset Formula $p(Y)$
\end_inset

, after some observation 
\begin_inset Formula $X$
\end_inset

, the probability of event 
\begin_inset Formula $Y$
\end_inset

 becomes the 
\emph on
posterior probability
\emph default
 
\begin_inset Formula $p(Y|X)$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are said to be 
\emph on
independent
\emph default
 if 
\begin_inset Formula $p(X,Y)=p(X)p(Y)$
\end_inset

, which is equivalent to 
\begin_inset Formula $P(Y|X)=p(Y)$
\end_inset

.
\end_layout

\begin_layout Subsection
Probability densities
\end_layout

\begin_layout Standard
If the probability that 
\begin_inset Formula $x$
\end_inset

 will lie in 
\begin_inset Formula $(a,b)$
\end_inset

 is given by 
\begin_inset Formula 
\[
p(x\in(a,b))=\int_{a}^{b}p(x)\d x
\]

\end_inset

then 
\begin_inset Formula $p(x)$
\end_inset

 is called the 
\emph on
probability density
\emph default
 over 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Standard
Apparently 
\begin_inset Formula $p(x)\geq0$
\end_inset

 and 
\begin_inset Formula $\int_{-\infty}^{\infty}p(x)\d x=1$
\end_inset

.
\end_layout

\begin_layout Standard
Under a nonlinear change of variable, a probability density transforms different
ly from a simple function, due to the Jacobian factor.
 If 
\begin_inset Formula $x=g(y)$
\end_inset

, since 
\begin_inset Formula $p_{x}(x)\d x=p_{y}(y)\d y$
\end_inset

, hence
\begin_inset Formula 
\begin{eqnarray}
p_{y}(y) & = & p_{x}(x)\left|\frac{\d x}{\d y}\right|\nonumber \\
 & = & p_{x}(g(y))\left|g'(y)\right|\label{eq:p_y(y)=p_x(...}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
The 
\emph on
cumulative distribution function
\emph default
 
\begin_inset Formula 
\[
P(z)=\int_{-\infty}^{z}p(x)\d x
\]

\end_inset


\end_layout

\begin_layout Standard
For several continuous variables 
\begin_inset Formula $x_{1},\ldots,x_{D}$
\end_inset

, denoted collectively by the vector 
\begin_inset Formula ${\bf x}$
\end_inset

, then we can define a joint probability density 
\begin_inset Formula $p({\bf x})$
\end_inset

 such that 
\begin_inset Formula $p\left({\bf x}\in({\bf x}_{0},{\bf x}_{0}+\delta{\bf x})\right)=p({\bf x}_{0})\delta{\bf x}$
\end_inset

.
\end_layout

\begin_layout Subsection
Expectations and covariances
\end_layout

\begin_layout Standard
The average value of some function 
\begin_inset Formula $f(x)$
\end_inset

 under a probability distribution 
\begin_inset Formula $p(x)$
\end_inset

 is called the 
\emph on
expectation
\emph default
 of 
\begin_inset Formula $f(x)$
\end_inset

 and denoted by 
\begin_inset Formula $\EE[f]$
\end_inset

.
 For a discrete distribution,
\begin_inset Formula 
\[
\EE[f]=\sum_{x}p(x)f(x)
\]

\end_inset

For continuous variables,
\begin_inset Formula 
\[
\EE[f]=\int p(x)f(x)\d x
\]

\end_inset

In either case, the expectation can be approximated given 
\begin_inset Formula $N$
\end_inset

 samples,
\begin_inset Formula 
\begin{equation}
\EE[f]\simeq\frac{1}{N}\sum_{n=1}^{N}f(x_{n})\label{eq:E[f] simeq}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
When considering expectations of functions of several variables, we use
 subscript to indicate which variable is being averaged over, e.g.
 
\begin_inset Formula $\EE_{x}[f(x,y)]$
\end_inset

 is a function of 
\begin_inset Formula $y$
\end_inset

.
\end_layout

\begin_layout Standard
We can also consider 
\emph on
conditional expectation
\begin_inset Formula 
\[
\EE_{x}[f|y]=\sum_{x}p(x|y)f(x)
\]

\end_inset


\end_layout

\begin_layout Standard
The 
\emph on
variance
\emph default
 of 
\begin_inset Formula $f(x)$
\end_inset

 is defined by
\begin_inset Formula 
\begin{eqnarray}
\var[f] & = & \EE\left[(f(x)-\EE[f(x)]\right]{}^{2}\nonumber \\
 & = & \EE\left[f(x)^{2}\right]-\EE\left[f(x)\right]{}^{2}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
The 
\emph on
covariance
\emph default
 of two random variable 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

 is defined by
\begin_inset Formula 
\begin{eqnarray}
\cov[x,y] & = & \EE_{x,y}\left[\{x-\EE[x]\}\{y-\EE[y]\}\right]\nonumber \\
 & = & \EE_{x,y}[xy]-\EE[x]\EE[y]
\end{eqnarray}

\end_inset

which expresses the extent to which 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

 vary together.
 If they are independent, then the covariance vanishes.
\end_layout

\begin_layout Standard
In the case of two vectors of random variables 
\begin_inset Formula ${\bf x}$
\end_inset

 and 
\begin_inset Formula ${\bf y}$
\end_inset

, the covariance is a matrix
\begin_inset Formula 
\begin{eqnarray}
\cov[{\bf x},{\bf y}] & = & \EE_{x,y}\left[\left\{ {\bf x}-\EE[{\bf x]}\right\} \left\{ {\bf y}\trans-\EE[{\bf y\trans]}\right\} \right]\nonumber \\
 & = & \EE_{x,y}[{\bf x}{\bf y}\trans]-\EE[{\bf x]}\EE[{\bf y\trans]}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Subsection
Bayesian probabilities
\end_layout

\begin_layout Standard
In the 
\emph on
classical
\emph default
 or 
\emph on
frequentist
\emph default
 interpretation of probability, probabilities is viewed in terms of the
 frequencies of random, repeatable events.
 In the more general 
\emph on
Beyesian
\emph default
 view, probabilities provide a quantification of uncertainty, so we can
 say the probability of an uncertain event, like whether the Arctic ice
 cap will have disappeared by the end of the century, which is not events
 that can be repeated.
\end_layout

\begin_layout Standard
In the polynomial curve fitting example, we assume the parameters 
\begin_inset Formula ${\bf w}$
\end_inset

 have a prior probability distribution 
\begin_inset Formula $p({\bf w})$
\end_inset

, then given the observed data 
\begin_inset Formula ${\cal D}$
\end_inset

, the posterior probability is
\begin_inset Formula 
\[
p({\bf w}|{\cal D})=\frac{p({\cal D}|{\bf w})p({\bf w)}}{p({\cal D})}
\]

\end_inset

where the quantity 
\begin_inset Formula $p({\cal D}|{\bf w})$
\end_inset

 is called the 
\emph on
likelihood function
\emph default
, which expresses how probable the observed data set is for different settings
 of the parameter vector 
\begin_inset Formula ${\bf w}$
\end_inset

.
 The likelihood is not a probability distribution over 
\begin_inset Formula ${\bf w}$
\end_inset

, and its integral does not necessarily equal one.
\end_layout

\begin_layout Standard
Given the definition of likelihood, we can state Bayes' theorem in words
\begin_inset Formula 
\[
\text{posterior}\propto\text{likelihood}\times\text{prior}
\]

\end_inset

where all of these quantities are viewed as functions of 
\begin_inset Formula ${\bf w}$
\end_inset

.
\end_layout

\begin_layout Standard
In the likelihood function 
\begin_inset Formula $p({\cal D}|{\bf w})$
\end_inset

, in the frequentist setting, 
\begin_inset Formula ${\bf w}$
\end_inset

 is considered to be a fixed parameter, whose value is determines by some
 form of `estimator', and error bars on this estimate are obtained by considerin
g the distribution of possible data sets 
\begin_inset Formula ${\cal D}$
\end_inset

.
 By contrast, from Bayesian viewpoint there is only a single data set 
\begin_inset Formula ${\cal D}$
\end_inset

 (the one actually observed), and the uncertainty in the parameters is expressed
 through a probability distribution over 
\begin_inset Formula ${\bf w}$
\end_inset

.
\end_layout

\begin_layout Subsection
The Gaussian distribution
\end_layout

\begin_layout Standard
The Gaussian distribution on a single real-valued variable 
\begin_inset Formula $x$
\end_inset

 is defined by
\begin_inset Formula 
\[
{\cal N}(x|\mu,\sigma^{2})=\frac{1}{(2\pi\sigma^{2})^{1/2}}\exp\left\{ -\frac{1}{2\sigma^{2}}(x-\mu)^{2}\right\} 
\]

\end_inset

which is governed by two parameters: 
\begin_inset Formula $\mu$
\end_inset

 the 
\emph on
mean
\emph default
 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

 the 
\emph on
variance
\emph default
.
 
\begin_inset Formula $\sigma$
\end_inset

 is called the 
\emph on
standard deviation
\emph default
, and 
\begin_inset Formula $\beta=1/\sigma^{2}$
\end_inset

 is called the 
\emph on
precision
\emph default
.
 The mean of 
\begin_inset Formula $x$
\end_inset

 is given by 
\begin_inset Formula $\EE[x]=\mu$
\end_inset

 and the variance of 
\begin_inset Formula $x$
\end_inset

 is given by 
\begin_inset Formula $\var[x]=\EE[x^{2}]-\EE[x]^{2}=\sigma^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
The Gaussian distribution defined over a 
\begin_inset Formula $D$
\end_inset

-dimensional vector 
\begin_inset Formula ${\bf x}$
\end_inset

 of continuous variables is given by
\begin_inset Formula 
\[
{\cal N}({\bf x}|{\bf \mu},{\bf \Sigma})=\frac{1}{(2\pi)^{D/2}}\frac{1}{\left|\bm{\Sigma}\right|^{1/2}}\exp\left\{ -\frac{1}{2}({\bf x}-\bm{\mu})\trans\bm{\Sigma}^{-1}({\bf x}-\bm{\mu})\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
Suppose we have a data set of observation 
\begin_inset Formula $\hv x=(x_{1},\ldots,x_{N})\trans$
\end_inset

 which is 
\emph on
independent and identically distributed
\emph default
 (often abbreviated to i.i.d.) from a Gaussian distribution.
 The likelihood of the data set, which is a function of 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

, is in the form
\begin_inset Formula 
\[
p\left(\hv x|\mu,\sigma^{2}\right)=\prod_{n=1}^{N}{\cal N}(x_{n}|\mu,\sigma^{2})
\]

\end_inset


\end_layout

\begin_layout Standard
One common criterion for determining the parameters in a probability distributio
n using an observed data set is to find the parameter values that maximize
 the likelihood function.
\end_layout

\begin_layout Standard
In practice, for mathematical and numerical reasons, it's more convenient
 to maximize the log of the likelihood functions
\begin_inset Formula 
\begin{equation}
\ln p\left(\hv x|\mu,\sigma^{2}\right)=-\frac{1}{2\sigma^{2}}\sum_{n=1}^{N}(x_{n}-\mu)^{2}-\frac{N}{2}\ln\sigma^{2}-\frac{N}{2}\ln(2\pi)\label{eq:ln p(x|mu,sigma^2)}
\end{equation}

\end_inset

 
\end_layout

\begin_layout Standard
Maximizing 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ln p(x|mu,sigma^2)"

\end_inset

 with respect to 
\begin_inset Formula $\mu$
\end_inset

 gives the maximum likelihood solution
\begin_inset Formula 
\[
\mu_{{\rm ML}}=\frac{1}{N}\sum_{n=1}^{N}x_{n}
\]

\end_inset

which is the 
\emph on
sample mean
\emph default
.
 Similarly, Maximize 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ln p(x|mu,sigma^2)"

\end_inset

 with respect to 
\begin_inset Formula $\sigma^{2}$
\end_inset

gives
\begin_inset Formula 
\[
\sigma_{{\rm ML}}^{2}=\frac{1}{N}\sum_{n=1}^{N}(x_{n}-\mu_{{\rm ML}})^{2}
\]

\end_inset

which is the 
\emph on
sample variance.
\end_layout

\begin_layout Standard
The maximum likelihood approach systematically underestimates the variance
 of the distribution.
 This is an example of a phenomenon called 
\emph on
bias
\emph default
 and is related to the problem of over-fitting encountered in the context
 of polynomial curve fitting.
 First, we note that 
\begin_inset Formula $\mu_{{\rm ML}}$
\end_inset

 and 
\begin_inset Formula $\sigma_{{\rm ML}}^{2}$
\end_inset

 are functions of the data set values 
\begin_inset Formula $x_{1},\ldots,x_{N}$
\end_inset

.
 Consider the expectations of these quantities with respect to the data
 set values, which themselves come from a Gaussian distribution with parameters
 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset


\begin_inset Formula 
\begin{eqnarray}
\EE[\mu_{{\rm ML}}] & = & \mu\\
\EE[\sigma_{{\rm ML}}^{2}] & = & \left(\frac{N-1}{N}\right)\sigma^{2}\label{eq:E[sigma_ML^2]}
\end{eqnarray}

\end_inset

so on average the maximum likelihood approach will underestimate the true
 variance by a factor 
\begin_inset Formula $(N-1)/N$
\end_inset

.
\end_layout

\begin_layout Standard
From 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:E[sigma_ML^2]"

\end_inset

 we see the following estimate for the variance parameter is unbiased
\begin_inset Formula 
\[
\widetilde{\sigma}^{2}=\frac{N}{N-1}\sigma_{{\rm ML}}^{2}=\frac{1}{N-1}\sum_{n=1}^{N}(x_{n}-\mu_{{\rm ML}})^{2}
\]

\end_inset

 this result arises automatically when we adopt a Bayesian approach (Section
 10.1.3).
\end_layout

\begin_layout Subsection
Curve fitting re-visited
\end_layout

\begin_layout Standard
The goal of curve fitting problem is to make predictions for the target
 variable 
\begin_inset Formula $t$
\end_inset

 given some new value of the input variable 
\begin_inset Formula $x$
\end_inset

 on the basis of a set of training data 
\begin_inset Formula $\hv x=(x_{1},\ldots,x_{N})\trans$
\end_inset

 and 
\begin_inset Formula $\hv t=(t_{1},\ldots,t_{N})\trans$
\end_inset

.
 We can express out uncertainty over the value of the target variable using
 a probability distribution.
 Assume that, given the value of 
\begin_inset Formula $x$
\end_inset

, the corresponding value of 
\begin_inset Formula $t$
\end_inset

 has a Gaussian distribution with a mean equal to the value 
\begin_inset Formula $y(x,{\bf w})$
\end_inset

 given by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:y(x,w)"

\end_inset

.
 Thus we have
\begin_inset Formula 
\begin{equation}
p(t|x,{\bf w},\beta)={\cal N}\left(t|y(x,{\bf w}),\beta^{-1}\right)\label{eq:p(t|x,w,beta)}
\end{equation}

\end_inset

 where 
\begin_inset Formula $\beta$
\end_inset

 is the precision parameter.
\end_layout

\begin_layout Standard
Use the training data 
\begin_inset Formula $\{\hv x,\hv t\}$
\end_inset

 to determine the values of the unknown parameters 
\begin_inset Formula ${\bf w}$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 by maximum likelihood, the likelihood function is
\begin_inset Formula 
\[
p(\hv t|\hv x,{\bf w},\beta)=\prod_{n=1}^{N}{\cal N}\left(t_{n}|y(x_{n},{\bf w}),\beta^{-1}\right)
\]

\end_inset

and its logarithm is
\begin_inset Formula 
\begin{equation}
\ln p(\hv t|\hv x,{\bf w},\beta)=-\frac{\beta}{2}\sum_{n=1}^{N}\left\{ y(x_{n},{\bf w})-t_{n}\right\} ^{2}+\frac{N}{2}\ln\beta-\frac{N}{2}\ln(2\pi)\label{eq:ln p(t|x,w,beta)}
\end{equation}

\end_inset

Maximizing 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ln p(t|x,w,beta)"

\end_inset

 with respect to 
\begin_inset Formula ${\bf w}$
\end_inset

 gives us 
\begin_inset Formula ${\bf w}_{{\rm ML}}$
\end_inset

, which is the same as minimize the 
\emph on
sum-of-squares error function
\emph default
 defined by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:E(w)"

\end_inset

.
\end_layout

\begin_layout Standard
Maximizing 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ln p(t|x,w,beta)"

\end_inset

 with respect to 
\begin_inset Formula $\beta$
\end_inset

 gives
\begin_inset Formula 
\[
\frac{1}{\beta_{{\rm ML}}}=\frac{1}{N}\sum_{n=1}^{N}\left\{ y(x_{n},{\bf w}_{{\rm ML}})-t_{n}\right\} ^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Having determined the parameters 
\begin_inset Formula ${\bf w}$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

, we can now make predictions for new values of 
\begin_inset Formula $x$
\end_inset

, and in probabilistic model, these are expressed in terms of the 
\emph on
predictive distribution
\emph default
 that gives the probability distribution over 
\emph on
t
\begin_inset Formula 
\[
p(t|x,{\bf w}_{{\rm ML}},\beta_{{\rm ML}})={\cal N}\left(t|y(x,{\bf w}_{ML}),\beta_{{\rm ML}}^{-1}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
In a more Bayesian approach, we introduce a Gaussian prior distribution
 over the polynomial coefficients 
\begin_inset Formula ${\bf w}$
\end_inset


\begin_inset Formula 
\begin{equation}
p({\bf w}|\alpha)={\cal N}({\bf w}|{\bf 0},\alpha^{-1}{\bf I})=\left(\frac{\alpha}{2\pi}\right)^{(M+1)/2}\exp\left\{ -\frac{\alpha}{2}{\bf w}\trans{\bf w}\right\} \label{eq:p(w|alpha)}
\end{equation}

\end_inset

where 
\begin_inset Formula $\alpha$
\end_inset

 is the precision of the distribution and 
\begin_inset Formula $M+1$
\end_inset

 is the number of elements in 
\begin_inset Formula ${\bf w}$
\end_inset

.
 Values such as 
\begin_inset Formula $\alpha$
\end_inset

, which controls the distribution of model parameters, are called 
\emph on
hyperparameters
\emph default
.
\end_layout

\begin_layout Standard
Using Bayes' theorem
\begin_inset Formula 
\begin{equation}
p({\bf w}|\hv x,\hv t,\alpha,\beta)\propto p(\hv t|\hv x,{\bf w},\beta)p({\bf w}|\alpha)\label{eq:p(w|x,t,alpha,beta)}
\end{equation}

\end_inset

We can now determine 
\begin_inset Formula ${\bf w}$
\end_inset

 by finding the most probable value of 
\begin_inset Formula ${\bf w}$
\end_inset

 given the data, in other words by maximizing the posterior distribution.
 This technique is called 
\emph on
maximum posterior
\emph default
, or simply 
\emph on
MAP
\emph default
.
\end_layout

\begin_layout Standard
Taking the negative logarithm of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:p(w|x,t,alpha,beta)"

\end_inset

 and combining with 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:ln p(t|x,w,beta)"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:p(w|alpha)"

\end_inset

, we find that the maximum of the posterior is given by the minimum of
\begin_inset Formula 
\[
\frac{\beta}{2}\sum_{n=1}^{N}\left\{ y(x_{n},{\bf w})-t_{n}\right\} ^{2}+\frac{\alpha}{2}{\bf w}\trans{\bf w}
\]

\end_inset

Thus we see that maximizing the posterior distribution is equivalent to
 minimizing the regularized sum-of-squares error function 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:regularized E(w)"

\end_inset

.
\end_layout

\begin_layout Subsection
Bayesian curve fitting
\end_layout

\begin_layout Standard
Although we have included a prior distribution 
\begin_inset Formula $p({\bf w}|\alpha)$
\end_inset

, we are still making a point estimate of 
\begin_inset Formula ${\bf w}$
\end_inset

 and so this does not yet amount to a Bayesian treatment.
 In a fully Bayesian approach, we should consistently apply the sum and
 product rules of probability, which requires, as we shall see shortly,
 that we integrate over all values of 
\begin_inset Formula ${\bf w}$
\end_inset

.
 Such marginalizations lie at the heart of Bayesian methods for pattern
 recognition.
\end_layout

\begin_layout Standard
In curve fitting, we are given the training data 
\begin_inset Formula $\{\hv x,\hv t\}$
\end_inset

, along with a new test point 
\begin_inset Formula $x$
\end_inset

, and our goal is to predict the value of 
\begin_inset Formula $t$
\end_inset

.
 Assuming the parameters 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 are fixed and known in advance by now, we wish the evaluate the predictive
 distribution 
\begin_inset Formula $p(t|\hv x,\hv t)$
\end_inset

.
 Using the product rules of probability
\begin_inset Formula 
\begin{equation}
p(t|x,\hv x,\hv t)=\int p(t|x,{\bf w})p({\bf w}|\hv x,\hv t)\d{\bf w}\label{eq:p(t|x,x,t)}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Here 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $p(t|x,{\bf w})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 and 
\begin_inset Formula $p({\bf w}|\hv x,\hv t)$
\end_inset

 are given by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:p(t|x,w,beta)"

\end_inset

 and normalizing the right-hand side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:p(w|x,t,alpha,beta)"

\end_inset

.
\end_layout

\begin_layout Standard
The calculation and integration in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:p(t|x,x,t)"

\end_inset

 can be performed analytically with the result in a Gaussian distribution
\begin_inset Formula 
\begin{equation}
p(t|x,\hv x,\hv t)={\cal N}\left(t|m(x),s^{2}(x)\right)\label{eq:p(t|x,x,t)=}
\end{equation}

\end_inset

where the mean and variance are given by
\begin_inset Formula 
\begin{eqnarray}
m(x) & = & \beta\bm{\phi}(x)\trans{\bf S}\sum_{n=1}^{N}\bm{\phi}(x_{n})t_{n}\\
s^{2}(x) & = & \beta^{-1}+\bm{\phi}(x)\trans{\bf S}\bm{\phi}(x)\label{eq:s^2(x)}
\end{eqnarray}

\end_inset

Here the matrix 
\begin_inset Formula ${\bf S}$
\end_inset

 is given by
\begin_inset Formula 
\[
{\bf S}^{-1}=\alpha{\bf I}+\beta\sum_{n=1}^{N}\bm{\phi}(x_{n})\bm{\phi}(x)\trans
\]

\end_inset

and we have defined the vector 
\begin_inset Formula $\bm{\phi}(x)$
\end_inset

 with elements 
\begin_inset Formula $\phi_{i}(x)=x^{i}$
\end_inset

 for 
\begin_inset Formula $i=0,\ldots,M$
\end_inset

.
\end_layout

\begin_layout Standard
The matrix and the mean of the predictive distribution in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:p(t|x,x,t)="

\end_inset

 is dependent on 
\begin_inset Formula $x$
\end_inset

.
 The first term in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:s^2(x)"

\end_inset

 represents the uncertainty due to the noise on the target variables, and
 the second term arises from the uncertainty in the parameters 
\begin_inset Formula ${\bf w}$
\end_inset

 and is a consequence of the Bayesian treatment.
\end_layout

\begin_layout Section
Model Selection
\end_layout

\begin_layout Standard
Model selection is to find the appropriate values of complexity parameters
 within a given model and to find the best model for a particular application.
\end_layout

\begin_layout Standard
Due to the problem of over-fitting, performance on the training set is not
 a good indicator of predictive performance.
 If data is plentiful, we can set aside a 
\emph on
validation set
\emph default
 for comparing models.
 If the model design is iterated many times using a limited size data set,
 some over-fitting to the validation data can occur so it may be necessary
 to keep aside a third 
\emph on
test set
\emph default
 on which the performance of the selected model is finally evaluated.
\end_layout

\begin_layout Standard
But the supply of data for training and testing will be limited.
 To use as much of the available data as possible for training, one solution
 is to use 
\emph on
cross-validation
\emph default
, which is, to divide the data into 
\begin_inset Formula $S$
\end_inset

 sets, and use 
\begin_inset Formula $S-1$
\end_inset

 sets for training and 
\begin_inset Formula $1$
\end_inset

 set for validation, in total 
\begin_inset Formula $S$
\end_inset

 runs.
 When 
\begin_inset Formula $S=N$
\end_inset

, it's called the 
\emph on
leave-one-out
\emph default
 technique.
\end_layout

\begin_layout Standard
One major drawback of cross-validation is that the number of training runs
 is increased by a factor of 
\begin_inset Formula $S$
\end_inset

, and this can be problematic when training is computationally expensive.
 And when there are multiple parameters to explore, required number of training
 runs is exponential in the number of parameters.
 We therefore need a measure of performance which depends only on the training
 data (i.e.
 not validation-based) and which does not suffer from bias due to over-fitting.
\end_layout

\begin_layout Standard
Historically various `information criteria' have been proposed that attempt
 to correct for the bias of maximum likelihood by the addition of a penalty
 term to compensate for the over-fitting of more complex models.
 For example, the 
\emph on
Akaike information criterion
\emph default
, or AIC, chooses the model for which the quantity
\begin_inset Formula 
\[
\ln p({\cal D}|{\bf w}_{{\rm ML}})-M
\]

\end_inset

is largest.
 Later we'll see how complexity penalties arise in a natural and principled
 way in a fully Bayesian approach.
\end_layout

\begin_layout Section
The Curse of Dimensionality
\end_layout

\begin_layout Standard
In the polynomial curve fitting example we had just one input variable 
\begin_inset Formula $x$
\end_inset

, but in practice we will deal with spaces of high dimensionality comprising
 many input variables.
 This poses some serious challenges and is an important factor influencing
 the design of pattern recognition techniques.
\end_layout

\begin_layout Standard
For example, a simple approach for classification is to divide the input
 space into regular cells and classify each cell independently.
 But the number of cells grows exponentially with the dimensionality of
 the space, so we need exponentially large quantity of training data in
 order to ensure that the cells are not empty, which is not practical in
 a space of more than a few variables.
 High-dimensional general polynomial curve fitting have similar problems,
 as 
\begin_inset Formula $D$
\end_inset

 the number of input variables increases, the number of independent coefficients
 grows proportionally to 
\begin_inset Formula $D^{M}$
\end_inset

 for a polynomial of order 
\begin_inset Formula $M$
\end_inset

.
\end_layout

\begin_layout Standard
Our geometrical intuitions formed from life can fail badly when we consider
 spaces of higher dimensionality.
 For example, consider a sphere of radius 
\begin_inset Formula $r=1$
\end_inset

 in a space of 
\begin_inset Formula $D$
\end_inset

 dimensions, the fraction of the volume of the sphere that lies between
 radius 
\begin_inset Formula $r=1-\epsilon$
\end_inset

 and 
\begin_inset Formula $r=1$
\end_inset

 is given by 
\begin_inset Formula $1-(1-\epsilon)^{D}$
\end_inset

.
 For large 
\begin_inset Formula $D$
\end_inset

, this fraction tends to 
\begin_inset Formula $1$
\end_inset

 even for small values of 
\begin_inset Formula $\epsilon$
\end_inset

.
 Thus, in spaces of high dimensionality, most of the volume of a sphere
 is concentrated in a thin shell near the surface! 
\end_layout

\begin_layout Standard
Similarly, consider Gaussian distribution in high-dimensional space.
 If we transform from Cartesian to polar coordinates, and then integrate
 out the directional variables, we obtain an expression for the density
 
\begin_inset Formula $p(r)$
\end_inset

 as a function of radius 
\begin_inset Formula $r$
\end_inset

 from the origin.
 We can see that for large 
\begin_inset Formula $D$
\end_inset

 the probability mass of the Gaussian is concentrated in a thin shell.
\end_layout

\begin_layout Standard
The severe difficulty that can arise in spaces of many dimensions is sometimes
 called the 
\emph on
curse of dimensionality
\emph default
.
 But it does not prevent us from finding effective techniques applicable
 to high-dimensional spaces.
 First, real data will often be confined to a region of the space having
 lower effective dimensionality, and in particular the directions over which
 important variations in the target variables occur may be so confined.
 Second, real data will typically exhibit some smoothness properties (at
 least locally) so that for the most part small changes in the input variables
 will produce small changes in the target variables, and so we can exploit
 local interpolation-like techniques to allow us to make predictions of
 the target variables for new values of the input variables.
 Successful pattern recognition techniques exploit one or both of these
 properties.
 For example, an application in manufacturing in which images are captured
 of identical planar objects on a conveyor belt, in which the goal is to
 determine their orientation.
 Each image is a point in a space whose dimensionality is determined by
 the number of pixels.
 But since there are three degrees of freedom of variability between images,
 actually a set of images will live on a three dimensional 
\emph on
manifold
\emph default
 embedded within the high-dimensional space.
\end_layout

\begin_layout Section
Decision Theory
\end_layout

\begin_layout Standard
Decision theory, when combined with probability theory, allows us to make
 optimal decisions in situations involving uncertainty.
\end_layout

\begin_layout Standard
Suppose we have an input vector 
\begin_inset Formula ${\bf x}$
\end_inset

 together with a corresponding vector 
\begin_inset Formula ${\bf t}$
\end_inset

 of target variables, and our goal is to predict 
\begin_inset Formula ${\bf t}$
\end_inset

 given a new value for 
\begin_inset Formula ${\bf x}$
\end_inset

.
 
\begin_inset Formula ${\bf t}$
\end_inset

 are continuous variables or class labels for regression and classification
 problems.
 The joint probability distribution 
\begin_inset Formula $p({\bf x},{\bf t})$
\end_inset

 provides a complete summary of the uncertainty associated with these variables.
 Determination of 
\begin_inset Formula $p({\bf x},{\bf t})$
\end_inset

 from a set of training data is an example of 
\emph on
inference
\emph default
 and is typically very difficult.
 In practice, what we need is the prediction of 
\begin_inset Formula ${\bf t}$
\end_inset

, or more generally take a specific action based on our understudying of
 values 
\begin_inset Formula ${\bf t}$
\end_inset

 is likely to take, and this aspect is the subject of decision theory.
\end_layout

\begin_layout Standard
Consider, for example, a medical diagnosis problem, we have a X-ray image
 input vector 
\begin_inset Formula ${\bf x}$
\end_inset

, and output value 
\begin_inset Formula $t$
\end_inset

 to be a binary variable such that 
\begin_inset Formula $t=0$
\end_inset

 corresponds to class 
\begin_inset Formula ${\cal C}_{1}$
\end_inset

, the presence of cancer, and 
\begin_inset Formula $t=1$
\end_inset

 corresponds to 
\begin_inset Formula ${\cal C}_{2}$
\end_inset

.
 The general inference problem involves determining the joint distribution
 
\begin_inset Formula $p({\bf x},{\cal C}_{k})$
\end_inset

, or equivalently 
\begin_inset Formula $p({\bf x},t)$
\end_inset

.
 Although this can be very useful and informative, in the end we must decide
 whether to give treatment, and we would like this choice to be optimal
 in some appropriate sense.
 This is the 
\emph on
decision
\emph default
 step.
\end_layout

\begin_layout Standard
When we obtained 
\begin_inset Formula ${\bf x}$
\end_inset

, we're interested in the probabilities of the two classes given the image,
 which are given by 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

, using Bayes' theorem, it can be expressed in the form
\begin_inset Formula 
\[
p({\cal C}_{k}|{\bf x})=\frac{p({\bf x}|{\cal C}_{k})p({\cal C}_{k})}{p({\bf x})}
\]

\end_inset

If our aim is to minimize the chance of assigning 
\begin_inset Formula ${\bf x}$
\end_inset

 to the wrong class, then intuitively we would choose the class having the
 higher posterior probability.
\end_layout

\begin_layout Subsection
Minimizing the misclassification rate
\end_layout

\begin_layout Standard
We need a rule to assign each value of 
\begin_inset Formula ${\bf x}$
\end_inset

 to one of the available classes.
 Such a rule will divide the input space into regions 
\begin_inset Formula ${\cal R}_{k}$
\end_inset

 called 
\emph on
decision regions
\emph default
, one for each class.
 The boundaries between decision regions are called 
\emph on
decision boundaries
\emph default
 or 
\emph on
decision surfaces
\emph default
.
\end_layout

\begin_layout Standard
In the case of two classes, the probability of misclassification is
\begin_inset Formula 
\begin{eqnarray}
p(\text{mistake}) & = & p({\bf x}\in{\cal R}_{1},{\cal C}_{2})+p({\bf x}\in{\cal R}_{2},{\cal C}_{1})\nonumber \\
 & = & \int_{{\cal R}_{1}}p({\bf x},{\cal C}_{2})\d{\bf x}+\int_{{\cal R}_{2}}p({\bf x},{\cal C}_{1})\d{\bf x}\label{eq:p(mistake)}
\end{eqnarray}

\end_inset

Clearly to minimize 
\begin_inset Formula $p(\text{mistake})$
\end_inset

 we should arrange that each 
\begin_inset Formula ${\bf x}$
\end_inset

 is assigned to whichever class has the smaller value of the integrand in
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:p(mistake)"

\end_inset

.
 Since 
\begin_inset Formula $p({\bf x},{\cal C}_{k})=p({\cal C}_{k}|{\bf x})p({\bf x})$
\end_inset

, it's equivalent to assign 
\begin_inset Formula ${\bf x}$
\end_inset

 to the class for which the posterior probability 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

 is largest.
\end_layout

\begin_layout Standard
For the more general case of 
\begin_inset Formula $K$
\end_inset

 classes, it's slightly easier to maximize the probability of being correct,
 which is given by
\begin_inset Formula 
\begin{eqnarray}
p(\text{correct}) & = & \sum_{k=1}^{K}p({\bf x}\in{\cal R}_{k},{\cal C}_{k})\nonumber \\
 & = & \sum_{k=1}^{K}\int_{{\cal R}_{k}}p({\bf x},{\cal C}_{k})\d{\bf x}
\end{eqnarray}

\end_inset

which is maximized when the regions 
\begin_inset Formula ${\cal R}_{k}$
\end_inset

 are chosen such that each 
\begin_inset Formula ${\bf x}$
\end_inset

 is assigned to the class for which 
\begin_inset Formula $p({\bf x},{\cal C}_{k})$
\end_inset

 or 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

 is the largest.
\end_layout

\begin_layout Subsection
Minimizing the expected loss
\end_layout

\begin_layout Standard
For many applications, different kinds of misclassifications lead to different
 penalty, which can be formalized through a 
\emph on
loss function
\emph default
, also called a 
\emph on
cost function
\emph default
, which is a single, overall measure of loss incurred in taking any of the
 available decisions or actions.
 Our goal is then to minimize the total loss incurred.
 Suppose 
\begin_inset Formula $L_{kj}$
\end_inset

 represents the loss when the true class is 
\begin_inset Formula ${\cal C}_{k}$
\end_inset

 and we assign the input to class 
\begin_inset Formula ${\cal C}_{j}$
\end_inset

, 
\begin_inset Formula $L$
\end_inset

 is called a 
\emph on
loss matrix
\emph default
.
\end_layout

\begin_layout Standard
The optimal solution is the one which minimizes the loss function.
 However, the loss function depends on the true class, which is unknown.
 So we seek instead of minimize the average loss respect to the distribution
 
\begin_inset Formula $p({\bf x},{\cal C}_{k})$
\end_inset

, which is given by
\begin_inset Formula 
\[
\EE[L]=\sum_{k}\sum_{j}\int_{{\cal R}_{j}}L_{kj}p({\bf x},{\cal C}_{k})\d{\bf x}
\]

\end_inset

Each 
\begin_inset Formula ${\bf x}$
\end_inset

 can be assigned to one of 
\begin_inset Formula ${\cal R}_{j}$
\end_inset

, which implies that for each 
\begin_inset Formula ${\bf x}$
\end_inset

 we should minimize 
\begin_inset Formula $\sum_{k}L_{kj}p({\bf x},{\cal C}_{k})$
\end_inset

.
 As before we can use the product rule 
\begin_inset Formula $p({\bf x},{\cal C}_{k})=p({\cal C}_{k}|{\bf x})p({\bf x})$
\end_inset

 to eliminate the common factor of 
\begin_inset Formula $p({\bf x})$
\end_inset

.
 Thus the decision rule that minimizes the expected loss is the one that
 assigns each new 
\begin_inset Formula ${\bf x}$
\end_inset

 to the class 
\begin_inset Formula $j$
\end_inset

 for which the quantity
\begin_inset Formula 
\[
\sum_{k}L_{kj}p({\bf x},{\cal C}_{k})
\]

\end_inset

is a minimum.
\end_layout

\begin_layout Subsection
The reject option
\end_layout

\begin_layout Standard
The classification errors arise from the regions of input space where the
 largest of the posterior probabilities 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

 is significantly less than unity, or equivalently where the joint distributions
 
\begin_inset Formula $p({\bf x},{\cal C}_{k})$
\end_inset

 have comparable values.
 These are the regions where we are relatively uncertain about class membership.
 In some applications, it will be appropriate to avoid making decisions
 on the difficult cases in anticipation of a lower error rate on those examples
 for which a classification decision is made.
 This is known as the reject option.
 We can achieve this by introducing a threshold 
\begin_inset Formula $\theta$
\end_inset

 and rejecting those inputs 
\begin_inset Formula ${\bf x}$
\end_inset

 for which the largest of the posterior probabilities 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

 is less than or equal to 
\begin_inset Formula $\theta$
\end_inset

.
\end_layout

\begin_layout Standard
We can easily extend the reject criterion to minimize the expected loss,
 when a loss matrix include the loss incurred when a reject decision is
 made.
\end_layout

\begin_layout Subsection
Inference and decision
\end_layout

\begin_layout Standard
We have broken the classification problem down into two separate stages,
 the 
\emph on
inference stage
\emph default
 in which we use training data to learn a model for 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

, and the subsequent 
\emph on
decision stage
\emph default
 in which we use these posterior probabilities to make optimal class assignments.
 In fact, we can identity three distinct approaches to solving decision
 problems.
\end_layout

\begin_layout Enumerate
\begin_inset Argument
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

label=(
\backslash
alph*)
\end_layout

\end_inset


\end_layout

\end_inset

First solve the inference problem of determining the class-conditional densities
 
\begin_inset Formula $p({\bf x}|{\cal C}_{k})$
\end_inset

.
 Also separately infer the prior class probabilities 
\begin_inset Formula $p({\cal C}_{k})$
\end_inset

.
 Then use Bayes' theorem to find the posterior class probabilities 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

.
 Equivalently, we can model the joint distribution 
\begin_inset Formula $p({\bf x},{\cal C}_{k})$
\end_inset

 directly and then normalize to obtain the posterior probabilities.
 Then we use decision theory to determine class membership.
 Approaches that explicitly or implicitly model the distribution of inputs
 as well as outputs are known as 
\emph on
generative models
\emph default
, because by sampling from them it is possible to generate synthetic data
 points in the data space.
\begin_inset CommandInset label
LatexCommand label
name "enu:generative models"

\end_inset


\end_layout

\begin_layout Enumerate
First solve the inference problem of determining the posterior class probabiliti
es 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

, and then use decision theory to assign each new 
\begin_inset Formula ${\bf x}$
\end_inset

 to one of the classes.
 Approaches that model the posterior probabilities directly are called 
\emph on
discriminative models
\emph default
.
\begin_inset CommandInset label
LatexCommand label
name "enu:discriminative models"

\end_inset


\end_layout

\begin_layout Enumerate
Find a function 
\begin_inset Formula $f({\bf x})$
\end_inset

, called a 
\emph on
discriminant function
\emph default
, which maps each input 
\begin_inset Formula ${\bf x}$
\end_inset

 directly onto a class label.
 In this case, probabilities play no role.
\begin_inset CommandInset label
LatexCommand label
name "enu:discriminant function"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Approach 
\begin_inset CommandInset ref
LatexCommand ref
reference "enu:generative models"

\end_inset

 is the most demanding, because for many applications 
\begin_inset Formula ${\bf x}$
\end_inset

 will have high dimensionality, and consequently we need a large training
 set in order to determine the class-conditional densities 
\begin_inset Formula $p({\bf x}|{\cal C}_{k})$
\end_inset

 or the joint distribution 
\begin_inset Formula $p({\bf x},{\cal C}_{k})$
\end_inset

 to reasonable accuracy.
 However, one advantage is it can also determine 
\begin_inset Formula $p({\bf x})$
\end_inset

.
 This can be useful for detecting new data points that have low probability
 under the model and for which the predictions may be of low accuracy, which
 is known as 
\emph on
outlier detection
\emph default
 or 
\emph on
novelty detection
\emph default
.
\end_layout

\begin_layout Standard
The class-conditional densities may contain a lot of structure that has
 little effect on the posterior probabilities, so in approach 
\begin_inset CommandInset ref
LatexCommand ref
reference "enu:discriminative models"

\end_inset

 we find the posterior probabilities 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

 directly.
\end_layout

\begin_layout Standard
Approach 
\begin_inset CommandInset ref
LatexCommand ref
reference "enu:discriminant function"

\end_inset

 is even simpler, in which we combine the inference and decision stages
 into a simple learning problem.
\end_layout

\begin_layout Standard
There are many powerful reasons for wanting to compute the posterior probabiliti
es 
\begin_inset Formula $p({\cal C}_{k}|{\bf x})$
\end_inset

 before making decisions:
\end_layout

\begin_layout Itemize
The loss matrix may be subjected to revision.
\end_layout

\begin_layout Itemize
The possibility of reject option.
\end_layout

\begin_layout Itemize
Compensating for class priors.
 Consider the medical X-ray problem, since cancer is rare, only 0.1% of our
 samples are in the cancer class.
 A classifier that assigned every point to the normal class would already
 achieve 99.9% accuracy and it would be difficult to avoid this trivial solution.
 Also, the learning algorithm will not be exposed to a broad range of examples
 in the cancer class and hence is not likely to generalize well.
 A balanced data set in which we have selected equal numbers of examples
 from each of the classes would allow us to find a more accurate model.
 However, we must compensate for the effects of our modifications to the
 training data.
 We can simply take the posterior probabilities obtained from our artificially
 balanced data set and first divide by the class fractions in that data
 set and then multiply by the class fractions in the population to which
 we wish to apply the model.
 Finally, we need to normalize to ensure that the new posterior probabilities
 sum to one.
 Note that this procedure cannot be applied if we have learned a discriminant
 function directly instead of determining posterior probabilities.
\end_layout

\begin_layout Itemize
Combining models.
 For complex applications, we can break the problem into a number of smaller
 subproblems each of which can be tackled by a separate model.
 For example in the medical X-ray problem, we may assume that the distribution
 of inputs for X-ray images 
\begin_inset Formula ${\bf x}_{\I}$
\end_inset

 and the blood data 
\begin_inset Formula ${\bf x}_{{\rm B}}$
\end_inset

 are independently, so that
\begin_inset Formula 
\[
p({\bf x}_{{\rm I}},{\bf x}_{{\rm B}}|{\cal C}_{k})=p({\bf x}_{{\rm I}}|{\cal C}_{k})p({\bf x}_{{\rm B}}|{\cal C}_{k})
\]

\end_inset

This is an example of 
\emph on
conditional independence
\emph default
 property.
 Then the posterior probability given both the data is given by
\begin_inset Formula 
\begin{eqnarray}
p({\cal C}_{k}|{\bf x}_{{\rm I}},{\bf x}_{{\rm B}}) & \propto & p({\bf x}_{{\rm I}},{\bf x}_{{\rm B}}|{\cal C}_{k})p({\cal C}_{k})\nonumber \\
 & \propto & p({\bf x}_{{\rm I}}|{\cal C}_{k})p({\bf x}_{{\rm B}}|{\cal C}_{k})p({\cal C}_{k})\nonumber \\
 & \propto & p({\cal C}_{k}|{\bf x}_{{\rm I}})p({\cal C}_{k}|{\bf x}_{{\rm B}})
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Subsection
Loss functions for regression
\end_layout

\begin_layout Standard
In regression problems, the decision stage consists of choosing a specific
 estimate 
\begin_inset Formula $y({\bf x})$
\end_inset

 of the value of 
\begin_inset Formula $t$
\end_inset

 for each input 
\begin_inset Formula ${\bf x}$
\end_inset

.
 Suppose that in doing so, we incur a loss 
\begin_inset Formula $L(t,y({\bf x}))$
\end_inset

.
 The expected loss is given by
\begin_inset Formula 
\[
\EE[L]=\iint L(t,y({\bf x}))p({\bf x},t)\d{\bf x}\d t
\]

\end_inset

A common choice of the loss function is the squared loss 
\begin_inset Formula $L(t,y({\bf x}))=\left\{ y({\bf x})-t\right\} ^{2}$
\end_inset

.
 In this case
\begin_inset Formula 
\[
\EE[L]=\iint\left\{ y({\bf x})-t\right\} ^{2}p({\bf x},t)\d{\bf x}\d t
\]

\end_inset

Our goal is to choose 
\begin_inset Formula $y({\bf x})$
\end_inset

 so as to minimize 
\begin_inset Formula $\EE[L]$
\end_inset

.
 If we assume a completely flexible function 
\begin_inset Formula $y({\bf x})$
\end_inset

, we can do this formally using the calculus of variations to give
\begin_inset Formula 
\[
\frac{\partial\EE[L]}{\partial y({\bf x})}=2\int\left\{ y({\bf x})-t\right\} p({\bf x},t)\d t=0
\]

\end_inset

Solving for 
\begin_inset Formula $y({\bf x})$
\end_inset

, and using the sum and product rules of probability, we obtain
\begin_inset Formula 
\[
y({\bf x})=\frac{\int t\, p({\bf x},t)\d t}{p({\bf x})}=\int tp(t|{\bf x})\d t=\EE_{t}[t|{\bf x}]
\]

\end_inset

which is the conditional average of 
\begin_inset Formula $t$
\end_inset

 conditioned on 
\begin_inset Formula ${\bf x}$
\end_inset

 and is known as the 
\emph on
regression function
\emph default
.
 It can readily be extended to multiple variables represented by the vector
 
\begin_inset Formula ${\bf t}$
\end_inset

, in which case the optimal solution is the conditional average 
\begin_inset Formula ${\bf y}({\bf x})=\EE_{{\bf t}}[{\bf t}|{\bf x}]$
\end_inset

.
\end_layout

\begin_layout Standard
The squared loss is not the only possible choice of loss function for regression.
 Indeed, there are situations in which squared loss can lead to very poor
 results and where we need to develop more sophisticated approaches.
 An important example concerns situations in which the conditional distribution
 
\begin_inset Formula $p(t|{\bf x})$
\end_inset

 is multimodal, as often arises in the solution of inverse problems.
 One simple generalization of the squared loss is the 
\emph on
Minkowski
\emph default
 loss, whose expectation is given by
\begin_inset Formula 
\[
\EE[L_{q}]=\iint\left|y({\bf x})-t\right|^{q}p({\bf x},t)\d{\bf x}\d t
\]

\end_inset

The minimum of 
\begin_inset Formula $\EE[L_{q}]$
\end_inset

 is given by the conditional mean for 
\begin_inset Formula $q=2$
\end_inset

, the conditional media for 
\begin_inset Formula $q=1$
\end_inset

, and the conditional mode for 
\begin_inset Formula $q\to0$
\end_inset

.
\end_layout

\begin_layout Section
Information Theory
\end_layout

\begin_layout Standard
Consider a discrete random variable 
\begin_inset Formula $x$
\end_inset

 and we ask how much information is received when we observe a specific
 value for this variable.
 The amount of information can be viewed as the `degree of surprise' on
 learning the value of 
\begin_inset Formula $x$
\end_inset

 therefore will depend on 
\begin_inset Formula $p(x)$
\end_inset

.
 We should look for a quantity 
\begin_inset Formula $h(x)$
\end_inset

 that is a monotonic function of the probability 
\begin_inset Formula $p(x)$
\end_inset

 and that expresses the information content.
 The form of 
\begin_inset Formula $h(\cdot)$
\end_inset

 can be found by noting that if we have two events 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

 that are unrelated, then the information gain from observing both of them
 should be the sum of the information gained from each of them separately,
 so that 
\begin_inset Formula $h(x,y)=h(x)+h(y)$
\end_inset

.
 Two unrelated events will be statistically independent and so 
\begin_inset Formula $p(x,y)=p(x)p(y)$
\end_inset

.
 From these two relationships, it is easily shown that 
\begin_inset Formula $h(x)$
\end_inset

 must be given by the logarithm of 
\begin_inset Formula $p(x)$
\end_inset

 and so we have
\begin_inset Formula 
\begin{equation}
h(x)=-\log_{2}p(x)\label{eq:h(x)}
\end{equation}

\end_inset

where the negative sign ensures that information is positive or zero.
 The choice of basis is arbitrary, and in the case of base of 
\begin_inset Formula $2$
\end_inset

, the units of 
\begin_inset Formula $h(x)$
\end_inset

 are bits.
\end_layout

\begin_layout Standard
Suppose that a sender wishes to transmit the value of a random variable
 to a receiver.
 The average amount of information that they transmit is obtained by taking
 the expectation of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:h(x)"

\end_inset

 with respect to 
\begin_inset Formula $p(x)$
\end_inset

 and is given by
\begin_inset Formula 
\[
\H[x]=-\sum_{x}p(x)\log_{2}p(x)
\]

\end_inset

This important quantity is called the 
\emph on
entropy
\emph default
 of the random variable 
\begin_inset Formula $x$
\end_inset

.
 Note that 
\begin_inset Formula $\lim_{p\to0}p\ln p=0$
\end_inset

 so we shall take 
\begin_inset Formula $p(x)\ln p(x)=0$
\end_inset

 whenever we encounter a value for 
\begin_inset Formula $x$
\end_inset

 such that 
\begin_inset Formula $p(x)=0$
\end_inset

.
\end_layout

\begin_layout Standard
The concept of entropy indeed possess useful properties.
 For example, the 
\emph on
noiseless coding theorem
\emph default
 states that the entropy is a lower bound on the number of bits needed to
 transmit the state of a random variable.
\end_layout

\begin_layout Standard
From now on, we shall switch to the use of natural logarithms in defining
 entropy, as this will provide a more convenient link with ideas elsewhere
 in this book.
 In this case, the entropy is measured in units of `nats' instead of bits,
 which differ simply by a factor of 
\begin_inset Formula $\ln2$
\end_inset

.
\end_layout

\begin_layout Standard
Actually, the concept of entropy has much earlier origins in physics through
 development in statical mechanics.
\end_layout

\begin_layout Standard
The minimum of entropy is 
\begin_inset Formula $0$
\end_inset

 when one of the 
\begin_inset Formula $p_{i}=1$
\end_inset

 and all other 
\begin_inset Formula $p_{j\not\not=i}=0$
\end_inset

.
 Using the Lagrange multiplier method, we can see the maximum of entropy
 
\begin_inset Formula $\H$
\end_inset

 is 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\ln M$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 when all of the 
\begin_inset Formula $p(x_{i})=1/M$
\end_inset

 where 
\begin_inset Formula $M$
\end_inset

 is the total number of states 
\begin_inset Formula $x_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
We can extend the definition of entropy to include distribution 
\begin_inset Formula $p(x)$
\end_inset

 over continuous variables 
\begin_inset Formula $x$
\end_inset

.
 First divide 
\begin_inset Formula $x$
\end_inset

 into bins of width 
\begin_inset Formula $\Delta$
\end_inset

.
 Then, assuming 
\begin_inset Formula $p(x)$
\end_inset

 is continuous, the 
\emph on
mean value theorem
\emph default
 tells us that, for each such bin, there must exist a value 
\begin_inset Formula $x_{i}$
\end_inset

 such that
\begin_inset Formula 
\[
\int_{i\Delta}^{(i+1)\Delta}p(x)\d x=p(x_{i})\Delta
\]

\end_inset

We can now quantize the continuous variable 
\begin_inset Formula $x$
\end_inset

 by assigning any value 
\begin_inset Formula $x$
\end_inset

 to the value 
\begin_inset Formula $x_{i}$
\end_inset

 whenever 
\begin_inset Formula $x$
\end_inset

 falls in the 
\begin_inset Formula $i^{{\rm th}}$
\end_inset

 bin.
 This gives a discrete distribution for which the entropy takes the form
\begin_inset Formula 
\begin{equation}
\H_{\Delta}=-\sum_{i}p(x_{i})\Delta\ln(p(x_{i})\Delta)=-\sum_{i}p(x_{i})\Delta\ln p(x_{i})-\ln\Delta\label{eq:H_Delta}
\end{equation}

\end_inset

Omit the second term 
\begin_inset Formula $-\ln\Delta$
\end_inset

 on the right-hand side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:H_Delta"

\end_inset

 and consider the limit 
\begin_inset Formula $\Delta\to0$
\end_inset

.
 The first term on the right-hand side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:H_Delta"

\end_inset

 will became
\begin_inset Formula 
\[
\lim_{\Delta\to0}\left\{ \sum_{i}p(x_{i})\Delta\ln p(x_{i})\right\} =-\int p(x)\ln p(x)\d x
\]

\end_inset

where the quantity on the right-hand side is called the 
\emph on
differential entropy
\emph default
.
 We see that the discrete and continuous forms of the entropy differ by
 a quantity 
\begin_inset Formula $\ln\Delta$
\end_inset

, which diverges in the limit 
\begin_inset Formula $\Delta\to0$
\end_inset

.
 This reflects the fact that to specify a continuous variable very precisely
 requires a large number of bits.
 For a density defined over multiple continuous variables, denoted collectively
 by the vector 
\begin_inset Formula ${\bf x}$
\end_inset

, the differential entropy is given by
\begin_inset Formula 
\[
\H[{\bf x}]=-\int p({\bf x})\ln p({\bf x})\d{\bf x}
\]

\end_inset


\end_layout

\begin_layout Standard
Let us now consider the maximum entropy configuration for a continuous variable.
 In order for this maximum to be well defined, it will be necessary to constrain
 the first and second moments of 
\begin_inset Formula $p(x)$
\end_inset

 as well as preserving the normalization constraint.
 We therefore maximize the differential entropy with the three constraints
\begin_inset Formula 
\begin{eqnarray}
\int_{-\infty}^{\infty}p(x)\d x & = & 1\\
\int_{-\infty}^{\infty}xp(x)\d x & = & \mu\\
\int_{-\infty}^{\infty}(x-\mu)^{2}p(x)\d x & = & \sigma^{2}
\end{eqnarray}

\end_inset

The constrained maximization can be performed using Lagrange multipliers,
 leading finally to the result
\begin_inset Formula 
\[
p(x)=\frac{1}{(2\pi\sigma^{2})^{1/2}}\exp\left\{ -\frac{(x-\mu)^{2}}{2\sigma^{2}}\right\} 
\]

\end_inset

and so the distribution that maximizes the differential entropy is the Gaussian.
 Note that we did not constrain the distribution to be nonnegative when
 we maximized the entropy.
 However, because the resulting distribution is indeed nonnegative, we see
 with hindsight that such a constraint is not necessary.
\end_layout

\begin_layout Standard
The differential entropy of the Gaussian is
\begin_inset Formula 
\[
\H[x]=\frac{1}{2}\left\{ 1+\ln(2\pi\sigma^{2})\right\} 
\]

\end_inset

Thus we see again that the entropy increases as the distribution becomes
 broader, i.e., as 
\begin_inset Formula $\sigma^{2}$
\end_inset

 increases.
 This result also shows that the differential entropy, unlike the discrete
 entropy, can be negative.
\end_layout

\begin_layout Standard
In a joint distribution 
\begin_inset Formula $p({\bf x},{\bf y})$
\end_inset

, if a value of 
\begin_inset Formula ${\bf x}$
\end_inset

 is already known, then the additional information needed to specify the
 corresponding value of 
\begin_inset Formula ${\bf y}$
\end_inset

 is given by 
\begin_inset Formula $-\ln p({\bf y}|{\bf x})$
\end_inset

.
 Thus the average additional information needed to specify can be written
 as
\begin_inset Formula 
\[
\H[{\bf y}|{\bf x}]=-\iint p({\bf y},{\bf x})\ln p({\bf y}|{\bf x})\d{\bf y}\d{\bf x}
\]

\end_inset

which is called the 
\emph on
conditional entropy
\emph default
 of 
\begin_inset Formula ${\bf y}$
\end_inset

 given 
\begin_inset Formula ${\bf x}$
\end_inset

.
 It is easily seen, using the product rule, that the conditional satisfies
 the relation
\begin_inset Formula 
\[
\H[{\bf x},{\bf y}]=\H[{\bf y}|{\bf x}]+\H[{\bf x}]
\]

\end_inset

Thus the information needed to describe 
\begin_inset Formula ${\bf x}$
\end_inset

 and 
\series bold

\begin_inset Formula ${\bf y}$
\end_inset


\series default
 is given by the sum of the information needed to describe 
\begin_inset Formula ${\bf x}$
\end_inset

 alone plus the additional information required to specify 
\series bold

\begin_inset Formula ${\bf y}$
\end_inset


\series default
 given 
\begin_inset Formula ${\bf x}$
\end_inset

.
\end_layout

\begin_layout Subsection
Relative entropy and mutual information
\end_layout

\begin_layout Standard
Consider some unknown distribution 
\begin_inset Formula $p({\bf x})$
\end_inset

, and suppose that we have modeled this using an approximating distribution
 
\begin_inset Formula $p({\bf x})$
\end_inset

.
 If we use 
\begin_inset Formula $q({\bf x})$
\end_inset

 to construct a coding scheme for the purpose of transmitting values of
 
\begin_inset Formula ${\bf x}$
\end_inset

 to a receiver, then the average 
\emph on
additional
\emph default
 amount of information (in nats) required to specify the value of 
\begin_inset Formula ${\bf x}$
\end_inset

 as a result of using 
\begin_inset Formula $q({\bf x})$
\end_inset

 instead of the true distribution 
\begin_inset Formula $p({\bf x})$
\end_inset

 is given by
\begin_inset Formula 
\begin{eqnarray}
\KL(p\|q) & = & -\int p({\bf x})\ln q({\bf x})\d{\bf x}-\left(-\int p({\bf x})\ln p({\bf x})\d{\bf x}\right)\nonumber \\
 & = & -\int p({\bf x})\ln\left\{ \frac{q({\bf x})}{p({\bf x})}\right\} \d{\bf x}\label{eq:KL(p||q)}
\end{eqnarray}

\end_inset

This is known as the 
\emph on
relative entropy
\emph default
 or 
\emph on
Kullback-Leibler divergence
\emph default
, or 
\emph on
KL divergence
\emph default
, between the distributions 
\begin_inset Formula $p({\bf x})$
\end_inset

 and 
\begin_inset Formula $q({\bf x})$
\end_inset

.
 Note that it is not a symmetrical quantity, that is to say 
\begin_inset Formula $\KL(p\|q)\not\equiv\KL(q\|p)$
\end_inset

.
\end_layout

\begin_layout Standard
The KL divergence satisfies 
\begin_inset Formula $\KL(p\|q)\geq0$
\end_inset

 with equality if and only if 
\begin_inset Formula $p({\bf x})=q({\bf x})$
\end_inset

.
 This can be proved by using 
\emph on
Jensen's inequality,
\emph default
 which is, a convex function 
\begin_inset Formula $f(x)$
\end_inset

 satisfies
\begin_inset Formula 
\begin{equation}
f\left(\sum_{i=1}^{M}\lambda_{i}x_{i}\right)\leq\sum_{i=1}^{M}\lambda_{i}f(x_{i})\label{eq:Jensen's inequality (discrete)}
\end{equation}

\end_inset

where 
\begin_inset Formula $\lambda_{i}\geq0$
\end_inset

 and 
\begin_inset Formula $\sum_{i}\lambda_{i}=1$
\end_inset

, for any set of points 
\begin_inset Formula $\{x_{i}\}$
\end_inset

.
 If we interpret 
\begin_inset Formula $\lambda_{i}=p(x_{i})$
\end_inset

 in a probability distribution over 
\begin_inset Formula $x$
\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Jensen's inequality (discrete)"

\end_inset

 can be written
\begin_inset Formula 
\[
f(\EE[x])\leq\EE[f(x)]
\]

\end_inset

where 
\begin_inset Formula $\EE[\cdot]$
\end_inset

 denotes the expectation.
 For continuous variables, Jensen's inequality takes the form
\begin_inset Formula 
\begin{equation}
f\left(\int{\bf x}p({\bf x})\d{\bf x}\right)\leq\int f({\bf x})p({\bf x})\d{\bf x}\label{eq:Jensens inequality}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Apply 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Jensens inequality"

\end_inset

 to the Kullback-Leibler divergence 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:KL(p||q)"

\end_inset

 to give
\begin_inset Formula 
\[
\KL(p\|q)=-\int p({\bf x})\ln\left\{ \frac{q({\bf x})}{p({\bf x})}\right\} \d{\bf x}\geq-\ln\int q({\bf x})\d{\bf x}=0
\]

\end_inset

where we have used the fact that 
\begin_inset Formula $-\ln x$
\end_inset

 is a convex function, together with the normalization condition 
\begin_inset Formula $\int q({\bf x})\d{\bf x}=1$
\end_inset

.
 In fact, 
\begin_inset Formula $-\ln x$
\end_inset

 is a strictly convex function, so the equality will hold if and only if
 
\begin_inset Formula $q({\bf x})=p({\bf x})$
\end_inset

 for all 
\begin_inset Formula ${\bf x}$
\end_inset

.
 Thus we can interpret the Kullback-Leibler divergence as a measure of the
 dissimilarity of the two distributions 
\begin_inset Formula $p({\bf x})$
\end_inset

 and 
\begin_inset Formula $q({\bf x})$
\end_inset

.
\end_layout

\begin_layout Standard
Suppose that data is being generated from an unknown distribution 
\begin_inset Formula $p({\bf x})$
\end_inset

 that we wish to model.
 We can try to approximate this distribution using some parametric distribution
 
\begin_inset Formula $q({\bf x}|\bm{\theta})$
\end_inset

, governed by a set of adjustable parameters 
\begin_inset Formula $\bm{\theta}$
\end_inset

, for example a multivariate Gaussian.
 One way to determine 
\begin_inset Formula $\bm{\theta}$
\end_inset

 is to minimize the KL divergence between 
\begin_inset Formula $p({\bf x})$
\end_inset

 and 
\begin_inset Formula $q({\bf x}|\bm{\theta})$
\end_inset

 with respect to 
\begin_inset Formula $\bm{\theta}$
\end_inset

.
 We cannot do this directly because we don't know 
\begin_inset Formula $p({\bf x})$
\end_inset

.
 Suppose, however, that we have observed a finite set of training points
 
\begin_inset Formula ${\bf x}_{n}$
\end_inset

, for 
\begin_inset Formula $n=1,\ldots,N$
\end_inset

, drawn from 
\begin_inset Formula $p({\bf x})$
\end_inset

.
 Then the expectation with respect to 
\begin_inset Formula $p({\bf x})$
\end_inset

 can be approximated by a finite sum over these points, using 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:E[f] simeq"

\end_inset

, so that
\begin_inset Formula 
\[
\KL(p\|q)\simeq\sum_{n=1}^{N}\left\{ -\ln q({\bf x}_{n}|\bm{\theta})+\ln p({\bf x}_{n})\right\} 
\]

\end_inset

The second term on the right-hand side is independent of 
\begin_inset Formula $\bm{\theta}$
\end_inset

, and the first term is the negative log likelihood function for 
\begin_inset Formula $\bm{\theta}$
\end_inset

 under the distribution 
\begin_inset Formula $q({\bf x}|\bm{\theta})$
\end_inset

 evaluated using the training set.
 Thus we see that minimizing the KL divergence is equivalent to maximizing
 the likelihood function.
\end_layout

\begin_layout Standard
If two sets of variables 
\begin_inset Formula ${\bf x}$
\end_inset

 and 
\begin_inset Formula ${\bf y}$
\end_inset

 given by 
\begin_inset Formula $p({\bf x},{\bf y})$
\end_inset

 are independent, then 
\begin_inset Formula $p({\bf x},{\bf y})=p({\bf x})p({\bf y})$
\end_inset

.
 If the variables are not independent, we can gain some idea of whether
 they are `close' to being independent by considering the KL divergence
 between 
\begin_inset Formula $p({\bf x},{\bf y})$
\end_inset

 and 
\begin_inset Formula $p({\bf x})p({\bf y})$
\end_inset

, given by
\begin_inset Formula 
\begin{eqnarray}
\I[{\bf x},{\bf y}] & \equiv & \KL(p({\bf x},{\bf y})\|p({\bf x})p({\bf y}))\nonumber \\
 & = & -\iint p({\bf x},{\bf y})\ln\left(\frac{p({\bf x})p({\bf y})}{p({\bf x},{\bf y})}\right)\d{\bf x}\d{\bf y}
\end{eqnarray}

\end_inset

which is called the 
\emph on
mutual information
\emph default
 between the variables 
\begin_inset Formula ${\bf x}$
\end_inset

 and 
\begin_inset Formula ${\bf y}$
\end_inset

.
 
\begin_inset Formula $\I({\bf x},{\bf y})\geq0$
\end_inset

 with equality if and only if 
\begin_inset Formula ${\bf x}$
\end_inset

 and 
\begin_inset Formula ${\bf y}$
\end_inset

 are independent.
 Use the sum and product rules of probability, we see that the mutual informatio
n is related to the conditional entropy through
\begin_inset Formula 
\[
\I[{\bf x},{\bf y}]=\H[{\bf x}]-\H[{\bf x}|{\bf y}]=\H[{\bf y}]-\H[{\bf y}|{\bf x}]
\]

\end_inset

Thus we can view the mutual information as the reduction in the uncertainty
 about 
\begin_inset Formula ${\bf x}$
\end_inset

 by virtue of being told the value of 
\begin_inset Formula ${\bf y}$
\end_inset

 (or vice versa).
 From a Bayesian perspective, we can view 
\begin_inset Formula $p({\bf x})$
\end_inset

 as the prior distribution for 
\begin_inset Formula ${\bf x}$
\end_inset

 and 
\begin_inset Formula $p({\bf x}|{\bf y})$
\end_inset

 as the posterior distribution after we have observed new data 
\begin_inset Formula ${\bf y}$
\end_inset

.
 The mutual information therefore represents the reduction in uncertainty
 about 
\begin_inset Formula ${\bf x}$
\end_inset

 as a consequence of the new observation 
\begin_inset Formula ${\bf y}$
\end_inset

.
\end_layout

\end_body
\end_document
